# ğŸ¥ SAM 2 Video Segmentation Pipeline

Este projeto demonstra como configurar, carregar e utilizar o modelo **SAM 2 (Segment Anything Model)**, da Meta AI, para segmentaÃ§Ã£o automÃ¡tica de objetos em vÃ­deos com o auxÃ­lio de cliques manuais para anotaÃ§Ã£o inicial.

## ğŸ“Œ Objetivo

Aplicar o modelo SAM 2 para segmentar objetos em vÃ­deos frame a frame com base em cliques positivos fornecidos manualmente. A pipeline inclui:
- PreparaÃ§Ã£o do ambiente (Colab)
- InstalaÃ§Ã£o das dependÃªncias
- Download e carregamento do checkpoint
- ExtraÃ§Ã£o dos frames do vÃ­deo
- InicializaÃ§Ã£o e inferÃªncia com SAM 2
- VisualizaÃ§Ã£o dos resultados
- ExportaÃ§Ã£o para vÃ­deo final segmentado

---

## ğŸ› ï¸ Tecnologias e Bibliotecas Utilizadas

- Python 3.10
- PyTorch 2.5.1
- Torchvision 0.20.1
- OpenCV
- Matplotlib
- SAM 2 (Facebook Research)
- ffmpeg (para extraÃ§Ã£o de frames)
- Google Colab (ambiente de execuÃ§Ã£o)

---

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente

Certifique-se de estar usando o Google Colab com `using_colab = True`. O notebook realiza a instalaÃ§Ã£o automÃ¡tica de todas as dependÃªncias necessÃ¡rias:

```python
!pip install opencv-python matplotlib 'git+https://github.com/facebookresearch/sam2.git'
!wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt
